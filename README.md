<p align="center">
  <img src="https://raw.githubusercontent.com/starman-tech/Orion-V1-2024/main/icon.svg" width="760"/>
</p>

<div align="center">

<pre style="display:inline-block; text-align:left;">
   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—
  â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘
  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘
  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
  â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘
   â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•â•
</pre>

</div>



<p align="center">
  <b>Hybrid AI Assistant Prototype</b><br/>
  <i>Local-first voice assistant combining STT, LLM and TTS with system automation.</i>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Made%20with-Python-blue?style=for-the-badge&logo=python">
  <img src="https://img.shields.io/badge/Type-Research%20Prototype-orange?style=for-the-badge">
  <img src="https://img.shields.io/badge/AI-STT%20%7C%20LLM%20%7C%20TTS-purple?style=for-the-badge">
</p>

<p align="center">
  <a href="https://discord.gg/nZtKJJtsyA">
    <img src="https://img.shields.io/badge/Discord-Join%20Community-5865F2?style=for-the-badge&logo=discord&logoColor=white">
  </a>
</p>

<hr style="border:1px solid #333"/>

<p align="center">
  âš¡ <b>Experimental Jarvis-like assistant for offline/online AI research</b> âš¡  
</p>

<p align="center">
  <img src="https://readme-typing-svg.demolab.com?font=Orbitron&size=22&pause=1000&color=08C5D1&center=true&vCenter=true&width=600&lines=STT+%E2%86%92+LLM+%E2%86%92+Commands+%E2%86%92+TTS;Local-first+AI+Assistant;System+Automation+with+Language">
</p>



---

# Orion-V1-2024


> Remarque : ce projet est un prototype personnel de type "Jarvis" Ã©crit en Python, crÃ©Ã© il y a ~2â€“3 ans. Beaucoup de techniques et d'API sont aujourd'hui datÃ©es ou fragiles, mais le code sert de base d'apprentissage pour bÃ¢tir un assistant hybride (STT + LLM + TTS) hors-ligne/en-ligne.

---

## ğŸ… Badges

[![License](https://img.shields.io/badge/License-MIT-blue.svg?style=flat-square)](https://opensource.org/licenses/MIT)
[![Version](https://img.shields.io/badge/Version-1.0.0-green.svg?style=flat-square)](https://github.com/starman-tech/Orion-V1-2024/releases)

---
## EnoncÃ© du problÃ¨me
Construire un assistant vocal local qui :
- Ã‰coute l'utilisateur (STT),
- Envoie du texte Ã  un moteur IA (clients Groq / OpenAI dans ce prototype),
- Extrait des commandes structurÃ©es renvoyÃ©es par l'IA,
- ExÃ©cute des actions systÃ¨me utiles (ouvrir applis/URLs, calendrier, Gmail, maps, capture image/screenshot),
- RÃ©pond Ã  voix (TTS).

Ce dÃ©pÃ´t assemble des composants open-source : STT (Vosk), TTS (gTTS ou OpenAI), clients IA (Groq/OpenAI), et des modules d'intÃ©gration systÃ¨me.

---

## Ce qui fonctionne (aujourd'hui)
- STT hors-ligne avec Vosk (modÃ¨les fournis dans models/ pour fr/en/es/it/de).
- TTS via gTTS (par dÃ©faut). Option OpenAI TTS si activÃ©e et configurÃ©e.
- Boucle conversationnelle de base : a_main.py (entrÃ©e -> get_response -> extract_commands -> execute -> speak).
- Changement de langue : module_language.load_model(lang).
- Parsing et exÃ©cution de commandes JSON-like (a_commands.py) : switch, gmail, calendar, websearch/open, image capture/screenshot, open app.
- Modules utilitaires inclus : module_google_search, module_mail, module_application_launcher, module_maps, module_screenshot/picture, module_injecteur (dangerux).
- ModÃ¨les Vosk "small" embarquÃ©s pour usage hors-ligne.

---

## Ce qui est obsolÃ¨te, fragile ou dangereux
- Appels Groq/OpenAI et noms de modÃ¨les (ex. "llama3-*", "gpt-4o") datent d'expÃ©rimentations : vÃ©rifiez et adaptez aux APIs actuelles.
- module_google_search scrappe google.com en HTML : fragile et susceptible de violer les ToS.
- module_application_launcher repose sur des hypothÃ¨ses OS et chemins codÃ©s â€” peut nÃ©cessiter adaptation par OS.
- module_injecteur installe des paquets et exÃ©cute du code gÃ©nÃ©rÃ© automatiquement â€” extrÃªmement dangereux. Ne l'activez pas sur une machine exposÃ©e.
- L'intÃ©gration calendrier / certaines fonctions peuvent Ãªtre incomplÃ¨tes selon l'Ã©tat du dÃ©pÃ´t.

---

## DÃ©marrage rapide (exÃ©cution locale)

1. Cloner le dÃ©pÃ´t :
   git clone https://github.com/starman-tech/Orion-V1-2024.git
   cd Orion-V1-2024

2. CrÃ©er et activer un environnement virtuel Python :
   python3 -m venv venv
   source venv/bin/activate  # macOS/Linux
   venv\Scripts\activate     # Windows (PowerShell: .\venv\Scripts\Activate.ps1)

3. Installer dÃ©pendances Python :
   pip install -r txt/requirements.txt

   DÃ©pendances systÃ¨me supplÃ©mentaires :
   - ffmpeg (nÃ©cessaire pour pydub)
     - Debian/Ubuntu: sudo apt-get install ffmpeg
     - macOS (Homebrew): brew install ffmpeg
     - Windows: installer ffmpeg et ajouter au PATH
   - Pilotes audio OS pour sounddevice

4. Configuration des clÃ©s API (recommandÃ© : variables d'environnement)
   - Ã‰ditez a_config.py pour qu'il lise les variables d'environnement (exemples ci-dessous),
     ou exportez les variables dans votre shell :
     - export OPENAI_API_KEY="sk_..."
     - export GROQ_API_KEY="..."

   Exemple minimal recommandÃ© (modifier a_config.py pour lire os.environ) :
   ```python
   import os
   from openai import OpenAI
   from groq import Groq

   openai_client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
   client = Groq(api_key=os.environ.get("GROQ_API_KEY"))
   ```

   - Pour Gmail : placez credentials.json dans module_mail/json/ et laissez le flux OAuth crÃ©er token.json lors du premier lancement.

5. Mode dÃ©veloppeur (entrÃ©e texte) :
   python a_main.py
   - a_main dÃ©marre en developer_mode = True (entrÃ©e texte).
   - Pour utiliser la reconnaissance vocale, passez developer_mode = False et veillez aux permissions micro.

6. Utilisation :
   - Tapez (ou dites) une requÃªte ; l'assistant renvoie une rÃ©ponse parlÃ©e si TTS actif et tente d'exÃ©cuter les commandes trouvÃ©es.

---

## Configuration (fichiers et variables clÃ©s)

Fichier principal de configuration : a_config.py

Variables importantes (Ã  adapter / dÃ©placer en variables d'environnement) :
- openai_client / client : clients OpenAI et Groq (injectez vos clÃ©s via os.environ).
- current_tts_engine : "gtts" (par dÃ©faut) ou "openai".
- current_ai_engine : moteur courant (ex. "llama3-70b-8192"); valeur initiale fournie dans a_config.py.
- current_tts_lang : langue TTS par dÃ©faut (ex. "fr").
- ai_engines : liste de moteurs disponibles (utilisÃ©e par switch_ai_engine).

Langues supportÃ©es : 'fr', 'en', 'es', 'it', 'de' via module_language.load_model(lang).

Gmail : module_mail s'attend Ã  module_mail/json/credentials.json pour OAuth et Ã©crit token.json Ã  cÃ´tÃ©.

---

## Commandes et exemples

Les rÃ©ponses IA peuvent contenir des tokens de commande encodÃ©s sous forme JSON-like :
Format dÃ©tectÃ© :
  ["command_type";"command"];{optional_params}

Exemples courants :
- Changer TTS :
  ["switch";"tts"]
- Changer d'IA :
  ["switch";"ai"]
- Changer de langue :
  ["switch";"language"];{"lang":"en"}
- Ouvrir une application :
  ["open";"app"];{"appname":"Visual Studio Code"}
- Ouvrir un site (ou chercher et ouvrir) :
  ["open";"websearch"];{"sitename":"github.com"}
  ["open";"web"];{"url":"https://example.com"}
- Envoyer un mail :
  ["gmail";"send"];{"to":"alice@example.com","subject":"Hello","message_text":"Texte"}
- Recherche Web (scraping, fragile) :
  ["web";"search"];{"query":"mÃ©tÃ©o Paris"}
- Prendre photo/screenshot :
  ["image";"capture"];{"prompt":"DÃ©cris ce que tu vois"}
  ["image";"screenshot"];{"prompt":"DÃ©cris l'Ã©cran"}

Le parsing est fait par a_commands.extract_commands et l'exÃ©cution dans execute_command. Les tokens sont retirÃ©s de la rÃ©ponse parlÃ©e par a_main aprÃ¨s exÃ©cution.

---

## Architecture et composants (aperÃ§u technique)

Composants principaux :
- a_main.py : boucle principale (mode texte/voix).
- STT : a_stt.py + module_language.py
  - Vosk (modÃ¨les dans models/) + sounddevice.
  - module_language.load_model(lang) charge le modÃ¨le Vosk correspondant (mise Ã  jour runtime).
- IA : a_ai.py
  - Wrapper client Groq (client.chat.completions.create) et fallback OpenAI (openai_client.chat.completions.create).
  - Fonctions de conversation et d'envoi d'images au modÃ¨le (encodage base64).
- Parsing & exÃ©cution : a_commands.py
  - extract_commands(text) : regex sur le pattern JSON-like.
  - execute_command(commands) : mapping vers modules (mail, maps, apps, image, calendar, switch, code).
- TTS : a_tts.py
  - gTTS + pydub (par dÃ©faut).
  - Option OpenAI TTS si configurÃ©e.
  - speak_in_chunks dÃ©coupe en phrases et joue sÃ©quentiellement.
- Modules d'intÃ©gration :
  - module_application_launcher : dÃ©tection applications et ouverture (Windows/macOS/Linux).
  - module_google_search : scraping Google et rÃ©cupÃ©ration texte de pages (fragile).
  - module_mail : auth Gmail, envoi et listing.
  - module_maps : recherche locale via geopy + routage OSRM.
  - module_screenshot / Picture : capture Ã©cran / photo (plateforme dÃ©pendante).
  - module_injecteur : installe dÃ©pendances et exÃ©cute code gÃ©nÃ©rÃ© (dangereux).

---

## Description des datasets inclus
Ce dÃ©pÃ´t ne contient pas de jeux de donnÃ©es d'entraÃ®nement LLM. Il inclut uniquement des modÃ¨les Vosk prÃ©-entraÃ®nÃ©s (petits) pour STT :
- vosk-model-small-fr-0.22
- vosk-model-small-en-us-0.15
- vosk-model-small-es-0.42
- vosk-model-small-it-0.22
- vosk-model-small-de-0.15

Aucun poids LLM ni donnÃ©es de fine-tuning ne sont fournis ici.

---

## DÃ©pendances (exactes du fichier txt/requirements.txt)
- gtts==2.3.2
- openai==0.27.0
- pydub==0.25.1
- vosk==0.3.45
- google-api-python-client==2.89.0
- google-auth==2.20.0
- google-auth-httplib2==0.1.0
- google-auth-oauthlib==1.0.0
- sounddevice==0.4.6
- requests==2.31.0
- httplib2==0.22.0
- numpy==1.24.4
- pytz==2023.3
- regex==2023.6.3
- groq==0.6.0

Notes :
- Certaines versions et APIs (openai/groq) ont pu changer depuis la crÃ©ation du projet â€” vÃ©rifiez la compatibilitÃ© avant mise en production.
- Installez ffmpeg pour pydub.

---

## RÃ©capitulatif des fonctions principales (description courte par fonction / mÃ©thode)
Ci-dessous des explications courtes et pratiques pour chaque fonction/mÃ©thode clÃ© (basÃ©es sur le code fourni).

- a_main.main()
  - Boucle principale : lecture entrÃ©e (texte ou micro), obtention rÃ©ponse via get_response, extraction/exÃ©cution commandes, et TTS via speak_in_chunks.

- a_stt.listen()
  - Ouvre un flux audio avec sounddevice (16 kHz) et Vosk pour retourner la premiÃ¨re transcription reconnue.

- module_language.load_model(lang)
  - Charge le modÃ¨le Vosk correspondant Ã  la langue demandÃ©e et met Ã  jour current_tts_lang. LÃ¨ve ValueError si langue non supportÃ©e.

- a_ai.get_response(user_input)
  - Ajoute un timestamp au message, l'ajoute Ã  chat_history, appelle le client IA (Groq par dÃ©faut, OpenAI si "gpt-4" dÃ©tectÃ©) et retourne la rÃ©ponse. Met la rÃ©ponse dans chat_history.

- a_ai.send_image_to_model(image_path, prompt)
  - Encode l'image locale en data URL (base64) et envoie un message multimodal au modÃ¨le via client.chat.completions.create; retourne la transcription/rÃ©sultat.

- a_ai.switch_ai_engine()
  - Parcourt ai_engines (depuis a_config) et bascule sur l'entrÃ©e suivante (rotatif).

- a_ai.get_response_from_Codeur(...) et get_response_from_Al(...)
  - Variantes pour envoyer des messages Ã  des "sous-discussions" (discussion/chat_history distincts) en utilisant openai_client.

- a_tts.speak_in_chunks(text)
  - DÃ©coupe le texte en phrases, convertit chaque phrase en audio (gTTS ou OpenAI TTS si activÃ©) puis joue sÃ©quentiellement via pydub.

- a_tts.switch_tts_engine()
  - Bascule entre "gtts" et "openai" (variable globale current_tts_engine).

- a_commands.extract_commands(text)
  - Extrait toutes les commandes selon le pattern regex '\["([^;]+)";"([^"]+)"\](?:;({.*?}))?' et retourne une liste de tuples (type, command, params).

- a_commands.execute_command(commands)
  - ItÃ¨re les commandes et appelle les modules appropriÃ©s : Gmail (send/list), open/app/web/websearch, switch (tts/ai/language), calendar (add/delete/update/reminder), web search/visit (module_google_search + get_response_from_Al), image capture/screenshot (Picture + send_image_to_model), code (module_injecteur + get_response_from_Codeur) â€” attention aux fonctions dangereuses.

- module_application_launcher.AppLauncher
  - DÃ©tecte applications selon OS et propose search_and_open_app(search_name) (recherche floue) et open_url_in_chrome(url). MÃ©thodes internes pour exÃ©cution cross-OS.

- module_google_search.google_search(query)
  - Scrappe les rÃ©sultats Google et retourne une liste de dicts {link, title, description, position}. Fragile.

- module_google_search.get_website_text(url)
  - RÃ©cupÃ¨re tout le texte d'une page via requests + BeautifulSoup.

- module_google_search.google_first_link(query)
  - Renvoie le premier lien d'une recherche Google (fragile).

- module_maps.LocalSearch.find_nearby_places(query, location, ...)
  - Recherche des lieux/localisation via geopy.Nominatim et filtre par distance. get_route start/destination via OSRM.

- module_mail.authenticate_gmail()
  - GÃ¨re le flux OAuth (credentials.json -> token.json) et retourne un service Gmail (googleapiclient).

- module_mail.create_message / send_email / list_recent_emails(service)
  - CrÃ©ation et envoi de message MIME, listing des derniers messages (ajoute expÃ©diteur au chat_history).

- module_injecteur.install_missing_dependencies(code)
  - Analyse imports et tente d'installer les libs manquantes via pip (danger : installation non contrÃ´lÃ©e).

- module_injecteur.execute_code_with_dependencies(code)
  - Installe dÃ©pendances dÃ©tectÃ©es, Ã©crit un temp_script.py et l'exÃ©cute, puis supprime le fichier (DANGEREUX).

- module_injecteur.generate_code / testr
  - Utilitaires pour Ã©crire du code et nettoyer une chaÃ®ne (usage interne au flux "code" du prototype).

---

## RÃ©sultats et mÃ©triques recommandÃ©es
Ce prototype n'inclut pas d'Ã©valuations formelles. Recommandations pour Ã©valuer localement :
- STT : mesurer le Word Error Rate (WER) sur un petit jeu de test enregistrÃ© (mÃªme acoustique/conditions).
- Parsing de commandes : construire un jeu de paires (utterance -> token attendu) et mesurer prÃ©cision/rappel de a_commands.extract_commands.
- Latence : mesurer temps total micro -> rÃ©ponse parlÃ©e (STT + AI + TTS) sur votre configuration matÃ©rielle.
- TTS : test subjectif (Ã©coute) ; gTTS intelligible mais basique.

---


## DÃ©pannage rapide
- Erreur Vosk ModelNotFound : vÃ©rifiez que les dossiers modÃ¨les sont dans models/ et que module_language.LANG_MODELS pointe vers les bons noms.
- Microphone non dÃ©tectÃ© : vÃ©rifier sounddevice list, permissions et pilotes.
- pydub / ffmpeg error : installer ffmpeg et l'ajouter au PATH.
- Erreurs Google API : vÃ©rifier module_mail/json/credentials.json et supprimer token.json pour rÃ©authentifier.
- Erreurs OpenAI/Groq : vÃ©rifiez variables d'environnement et compatibilitÃ©s des versions clients.

---

## Points incomplets / Ã  vÃ©rifier dans le code source
- module_application_launcher fait des hypothÃ¨ses (nom Chrome, chemins Windows). Tester et ajuster selon votre OS.
- module_google_search dÃ©pend du HTML de Google â€” prÃ©fÃ©rer APIs officielles.

---

## Licence & statut
- Prototype personnel â€” code fourni "as-is".
- Archivage du projet : ce dÃ©pÃ´t est archivÃ© depuis 2023.

---
